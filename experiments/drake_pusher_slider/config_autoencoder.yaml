env:
  type: "DrakePusherSlider"
  model_name: "sugar_box"
  table:
    size: [0.8, 0.8, 0.1]
    color: [0.5, 0.5, 0.5, 1.] # RGBA
    coulomb_friction: [0.9, 0.8] # static, dynamic friction
  mbp_dt: 0.001 # dt for multibody plant
  step_dt: 0.1 # 10Hz
  target_realtime_rate: 1.0
  rgbd_sensors:
    enabled: True
    sensor_list:
      camera_1_top_down: # top down view
        width: 640
        height: 480
        fov_y: 0.7051130178057091 # 40.4 degrees, from d415 specs https://www.intelrealsense.com/stereo-depth-modules-and-processors/
        z_near: 0.0 # should probably just leave these so it's perfect
        z_far: 10.0 # if they are -1 then use defaults
        pos: [0.        , 0.        , 1.2]
        quat: [ 0.00725556, -0.70699354,  0.70715023, -0.00678551]
      camera_2_top_down_rotated: # top down view
        width: 640
        height: 480
        fov_y: 0.7051130178057091 # 40.4 degrees, from d415 specs https://www.intelrealsense.com/stereo-depth-modules-and-processors/
        z_near: 0.0 # should probably just leave these so it's perfect
        z_far: 10.0 # if they are -1 then use defaults
        pos: [0.        , 0.        , 1.2]
        quat: [-2.90391680e-04,  9.99942179e-01,  4.11730214e-03,  9.92985244e-03]
  observation:
    rgbd: True # whether to store image observations or not


dataset:
  num_episodes: 500 # only used during data generation
  num_episodes_per_file: 10 # only used during data generation
  max_num_episodes: -1 # optional max num episodes when loading dataset, used for trimming datset
  num_timesteps: 30 # only used during data generation
  state_dim: 19 # pusher position-3D (3) + 5 descriptor keypoints (3D)
  action_dim: 2 # pusher velocity-2D
  data_generation:
    exploration_type: "random"
  data_augmentation:
    enabled: False
  action_function:
    type: "drake_pusher_velocity"
  observation_function:
    type: "drake_pusher_position_3D"
  visual_observation_function:
    type: "convolutiona_autoencoder"
    camera_name: "camera_1_top_down"
  visual_observation:
    enabled: False
  object_state_shape: [1,16]
  robot_state_shape: [1,3]


dynamics_net:
  model_type: "mlp"

perception:
  type: "ConvolutionalAutoender"
  camera_name: "camera_1_top_down"
  height: 64
  width: 64
  z_dim: 32
  channel_dim: 3 # input channel dimension


train_dynamics:
  random_seed: 1
  n_epoch: 500
  lr: 1e-4
  adam_beta1: 0.9
  batch_size: 32
  batch_norm: False
  nf_hidden: 500
  num_workers: 20
  train_valid_ratio: 0.5
  valid_frequency: 5 # validate after this many training epochs
  log_per_iter: 50
  ckp_per_iter: 10000
  resume_epoch: -1
  resume_iter: -1
  n_history: 1
  n_rollout: 10
#  lr_scheduler:
#    type: "ReduceLROnPlateau"
#    patience: 10 # epochs
#    factor: 0.1 # reduce LR by this factor
#    threshold: 1e-4
#    threshold_mode: "rel" # can be ["rel", "abs"]
#    cooldown: 5
#    min_lr: 1e-8
  lr_scheduler:
    type: "StepLR"
    enabled: True
    step_size: 300 # epochs
    gamma: 0.1 # reduce LR by this factor

  valid_loss_type: 'loss'


# used for vision only stuff
train_autoencoder:
  random_seed: 42
  n_epoch: 100
  lr: 1e-4
  adam_beta1: 0.9
  batch_size: 16
  num_workers: 12
  train_valid_ratio: 0.5
  log_per_iter: 100
  ckp_per_iter: 5000
  img_save_per_iter: 5000
  resume_epoch: -1
  resume_iter: -1
  lr_scheduler:
    enabled: False
    type: "ReduceLROnPlateau"
    patience: 10 # epochs
    factor: 0.1 # reduce LR by this factor
    threshold: 1e-4
    threshold_mode: "rel" # can be ["rel", "abs"]
    cooldown: 5
    min_lr: 1e-8
  loss_function:
    l2_recon:
      enabled: True
      weight: 1.0
    l2_recon_masked:
      enabled: False
      weight: 1.0


loss_function:
  mse_final_step:
    enabled: False
    weight: 1.0

  mse:
    enabled: True
    weight: 1.0

  smooth_l1:
    enabled: False
    weight: 1.0

  smooth_l1_final_step:
    enabled: False
    weight: 1.0

  # for the autoencoder loss
  l2_recon:
    enabled: True
    weight: 1.0
